{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c711483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from multiprocessing import Process,Manager\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import models\n",
    "import data\n",
    "import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499a047-f928-4276-b810-ec3664fbdbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3cf2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Set the random seed manually for reproductibility.\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b95f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20254a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of items:20101\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "loader = data.DataLoader('ml-20m')\n",
    "\n",
    "n_items = loader.load_n_items()\n",
    "train_data = loader.load_data('train')\n",
    "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
    "test_data_tr, test_data_te = loader.load_data('test')\n",
    "\n",
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "print(\"# of items:{}\".format(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a233eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:MultiVAE(\n",
      "  (q_layers): ModuleList(\n",
      "    (0): Linear(in_features=20101, out_features=600, bias=True)\n",
      "    (1): Linear(in_features=600, out_features=400, bias=True)\n",
      "  )\n",
      "  (p_layers): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=600, bias=True)\n",
      "    (1): Linear(in_features=600, out_features=20101, bias=True)\n",
      "  )\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "\n",
      "Layer: q_layers.0.weight | Size: torch.Size([600, 20101]) | Values : tensor([[-0.0020, -0.0059, -0.0157,  ...,  0.0019,  0.0114,  0.0084],\n",
      "        [ 0.0109,  0.0066, -0.0101,  ..., -0.0036, -0.0175, -0.0043]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: q_layers.0.bias | Size: torch.Size([600]) | Values : tensor([-0.0006, -0.0001], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: q_layers.1.weight | Size: torch.Size([400, 600]) | Values : tensor([[-0.0276,  0.0433,  0.0281,  ..., -0.1540,  0.0572, -0.0212],\n",
      "        [ 0.1012,  0.0527,  0.0555,  ...,  0.0192,  0.0471,  0.0580]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: q_layers.1.bias | Size: torch.Size([400]) | Values : tensor([0.0003, 0.0015], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: p_layers.0.weight | Size: torch.Size([600, 200]) | Values : tensor([[-0.1088, -0.0211, -0.0031, -0.0165,  0.0064, -0.0164,  0.0006, -0.0407,\n",
      "         -0.0241, -0.0691,  0.0793, -0.0044, -0.0262, -0.0073, -0.0052, -0.0579,\n",
      "          0.0610, -0.0608, -0.1029,  0.0195, -0.0031,  0.0141,  0.0296, -0.0950,\n",
      "         -0.0217,  0.0287, -0.0426, -0.0729,  0.1009,  0.0567,  0.0476,  0.0663,\n",
      "         -0.0002,  0.0981,  0.0593,  0.0163, -0.0068,  0.0218,  0.0240,  0.0603,\n",
      "         -0.0558,  0.0193,  0.0562, -0.0158, -0.0501, -0.0285, -0.0577, -0.0566,\n",
      "         -0.0694, -0.0294,  0.0290,  0.0207, -0.0223,  0.0212,  0.0264,  0.0328,\n",
      "          0.0003,  0.0147,  0.0290, -0.0148,  0.0258, -0.0868,  0.0238,  0.0957,\n",
      "          0.0425, -0.0114,  0.0166,  0.0040, -0.0305, -0.0606,  0.0154, -0.0076,\n",
      "         -0.0551, -0.0048, -0.0385, -0.0205, -0.0403, -0.0471, -0.0270, -0.0065,\n",
      "         -0.0290,  0.1111, -0.0977, -0.0414, -0.0356,  0.0320,  0.1057, -0.0083,\n",
      "         -0.0877,  0.0470,  0.0223,  0.0026,  0.0185,  0.0154, -0.0349, -0.0138,\n",
      "         -0.0596, -0.0401,  0.0399,  0.0068,  0.0571, -0.0456,  0.0465, -0.0253,\n",
      "         -0.0443, -0.0404,  0.0316, -0.0347,  0.0217, -0.0115, -0.0080, -0.0030,\n",
      "          0.0162,  0.0015,  0.0522, -0.0431, -0.0590, -0.1007, -0.0404,  0.1017,\n",
      "         -0.0649,  0.0331,  0.0139, -0.0245, -0.0840,  0.0492,  0.0258,  0.0153,\n",
      "          0.0342, -0.0737,  0.0070,  0.0527,  0.0568, -0.0137, -0.0165,  0.0553,\n",
      "         -0.0271,  0.1288, -0.0597,  0.0028, -0.0519,  0.0230, -0.0033, -0.0131,\n",
      "         -0.0371, -0.0805,  0.1053, -0.1567, -0.0452,  0.0018,  0.0294,  0.0061,\n",
      "         -0.0105,  0.0991,  0.0346,  0.0029,  0.0663,  0.0007, -0.0140, -0.0423,\n",
      "         -0.0505, -0.0901, -0.0589,  0.0476, -0.0358,  0.0500, -0.0468, -0.0104,\n",
      "         -0.0075, -0.0806,  0.0479, -0.0605, -0.0199, -0.0176, -0.0284,  0.0241,\n",
      "         -0.1147, -0.0428, -0.0861,  0.0949, -0.0069, -0.0503,  0.0240,  0.1004,\n",
      "          0.0551, -0.0260, -0.0446, -0.0606,  0.0431, -0.0080,  0.0085, -0.0137,\n",
      "         -0.0032,  0.0524,  0.1057,  0.0019, -0.0371,  0.0154,  0.0912,  0.0499],\n",
      "        [ 0.0210, -0.0377, -0.0629,  0.0639,  0.0710, -0.0730,  0.0372,  0.0433,\n",
      "         -0.0671, -0.0258, -0.0284,  0.0301,  0.0421, -0.0146, -0.0334, -0.0475,\n",
      "          0.0168, -0.0481, -0.0527, -0.0291,  0.0318, -0.0394, -0.0002, -0.0031,\n",
      "         -0.0064,  0.0694,  0.0510,  0.0674,  0.1239,  0.0433,  0.0601,  0.0678,\n",
      "         -0.0395, -0.0799,  0.0071, -0.0966,  0.0640,  0.0663, -0.0688,  0.0486,\n",
      "         -0.0426,  0.0682, -0.0039,  0.0285, -0.0063, -0.0664,  0.0545, -0.0151,\n",
      "          0.0545, -0.0273,  0.0194, -0.0577, -0.0618,  0.0040,  0.0688,  0.1163,\n",
      "         -0.0164,  0.0193,  0.0029,  0.0347,  0.0737,  0.0462,  0.0194, -0.0059,\n",
      "          0.0572, -0.0147, -0.0041, -0.0096,  0.0514, -0.0023,  0.1018,  0.0345,\n",
      "          0.0234,  0.0219, -0.0532, -0.0265,  0.1036, -0.0483,  0.0078, -0.0147,\n",
      "          0.0159, -0.0243, -0.0514, -0.1054,  0.0499,  0.0397, -0.0690, -0.0873,\n",
      "         -0.0147,  0.0102,  0.0187,  0.0323, -0.0033, -0.0325, -0.0263,  0.0673,\n",
      "          0.0215,  0.0322,  0.0312, -0.0673,  0.0616, -0.0217,  0.0753,  0.0447,\n",
      "          0.0438,  0.0288,  0.0861,  0.0057, -0.0184, -0.0078, -0.0138, -0.0193,\n",
      "         -0.0695, -0.0285, -0.0245, -0.0099,  0.0045, -0.0420,  0.0318,  0.0149,\n",
      "         -0.0499,  0.0280, -0.0759, -0.0359, -0.0006,  0.0411,  0.0500,  0.0066,\n",
      "          0.0422,  0.0836,  0.0039, -0.0348,  0.0204,  0.0746, -0.0550,  0.0176,\n",
      "         -0.0642,  0.0458,  0.0213, -0.0135,  0.0244, -0.0620, -0.0471, -0.0774,\n",
      "         -0.0395, -0.0047,  0.0141,  0.1016,  0.0189, -0.0218,  0.0005,  0.0475,\n",
      "         -0.0325, -0.0428, -0.0040, -0.0574, -0.0006, -0.0022,  0.0053, -0.0943,\n",
      "         -0.0592,  0.0329,  0.0035, -0.0493, -0.0709,  0.0394,  0.0715, -0.0156,\n",
      "         -0.1426,  0.0061,  0.0189, -0.0175, -0.0076, -0.0335, -0.0152,  0.0675,\n",
      "         -0.0325,  0.0072,  0.0525,  0.0795,  0.0711,  0.0796, -0.0130, -0.0740,\n",
      "          0.0908, -0.0304, -0.1124,  0.0270, -0.0271,  0.1065,  0.0116, -0.1105,\n",
      "         -0.0841, -0.0786,  0.0733, -0.1071, -0.0155, -0.0074, -0.0395,  0.0456]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: p_layers.0.bias | Size: torch.Size([600]) | Values : tensor([-0.0005, -0.0020], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: p_layers.1.weight | Size: torch.Size([20101, 600]) | Values : tensor([[-0.0071, -0.0024,  0.0100,  ...,  0.0018,  0.0088, -0.0037],\n",
      "        [ 0.0147,  0.0007, -0.0084,  ..., -0.0145, -0.0198,  0.0013]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: p_layers.1.bias | Size: torch.Size([20101]) | Values : tensor([0.0003, 0.0010], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "p_dims = [200, 600, n_items]\n",
    "model = models.MultiVAE(p_dims).to(device)\n",
    "\n",
    "print(f\"Model Structure:{model}\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.00)\n",
    "criterion = models.loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fcf582-afc3-45aa-bb09-44d7a250f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorboardX Writer\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190bee1-0d8a-4738-a998-bbf66ae68880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cffc33d-a12b-4704-aa18-9956c9dd6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "TOTAL_ANNEAL_STEPS = 200000\n",
    "ANNEAL_CAP = 0.2\n",
    "LOG_INTERVAL = 100\n",
    "EPOCHS = 2\n",
    "# EPOCHS = 200\n",
    "SAVE_PATH = 'model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e9a5898-5c51-4c4b-b361-41185fd6294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse2torch_sparse(data):\n",
    "    \"\"\"\n",
    "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
    "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
    "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
    "    \"\"\"\n",
    "    samples = data.shape[0]\n",
    "    features = data.shape[1]\n",
    "    coo_data = data.tocoo()\n",
    "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
    "    row_norms_inv = 1 / np.sqrt(data.sum(1))\n",
    "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
    "    values = np.array([row2val[r] for r in coo_data.row])\n",
    "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33bfa8a2-9c1b-475c-a9dc-6527f09aee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "718bbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    global update_count\n",
    "\n",
    "    np.random.shuffle(idxlist)\n",
    "    \n",
    "    for batch_idx, start_idx in enumerate(range(0, N, BATCH_SIZE)):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, N)\n",
    "        data = train_data[idxlist[start_idx:end_idx]]\n",
    "        data = naive_sparse2tensor(data).to(device)\n",
    "\n",
    "        if TOTAL_ANNEAL_STEPS > 0:\n",
    "            anneal = min(ANNEAL_CAP, \n",
    "                            1. * update_count / TOTAL_ANNEAL_STEPS)\n",
    "        else:\n",
    "            anneal = ANNEAL_CAP\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        loss = criterion(recon_batch, data, mu, logvar, anneal)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        update_count += 1\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
    "                    'loss {:4.2f}'.format(\n",
    "                        epoch, batch_idx, len(range(0, N, BATCH_SIZE)),\n",
    "                        elapsed * 1000 / LOG_INTERVAL,\n",
    "                        train_loss / LOG_INTERVAL))\n",
    "            \n",
    "            # Log loss to tensorboard\n",
    "            n_iter = (epoch - 1) * len(range(0, N, BATCH_SIZE)) + batch_idx\n",
    "            writer.add_scalars('data/loss', {'train': train_loss / LOG_INTERVAL}, n_iter)\n",
    "\n",
    "            start_time = time.time()\n",
    "            train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0058f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_tr, data_te):\n",
    "    # Turn on evaluation mode\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    global update_count\n",
    "    e_idxlist = list(range(data_tr.shape[0]))\n",
    "    e_N = data_tr.shape[0]\n",
    "    n100_list = []\n",
    "    r20_list = []\n",
    "    r50_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, e_N, BATCH_SIZE):\n",
    "            end_idx = min(start_idx + BATCH_SIZE, N)\n",
    "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
    "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
    "    \n",
    "            # cno : avoid users who have no clicks in heldout_data\n",
    "            u_idxlist_wo_any_iteracts = [i for i, x in enumerate(heldout_data.toarray().sum(axis=1)) if x >0]\n",
    "            data = data[u_idxlist_wo_any_iteracts]\n",
    "            heldout_data = heldout_data[u_idxlist_wo_any_iteracts]\n",
    "            \n",
    "            data_tensor = naive_sparse2tensor(data).to(device)\n",
    "\n",
    "            if TOTAL_ANNEAL_STEPS > 0:\n",
    "                anneal = min(ANNEAL_CAP, \n",
    "                               1. * update_count / TOTAL_ANNEAL_STEPS)\n",
    "            else:\n",
    "                anneal = ANNEAL_CAP\n",
    "\n",
    "            recon_batch, mu, logvar = model(data_tensor)\n",
    "\n",
    "            loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Exclude examples from training set\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            recon_batch[data.nonzero()] = -np.inf\n",
    "\n",
    "            n100 = metric.NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n",
    "            r20 = metric.Recall_at_k_batch(recon_batch, heldout_data, 20)\n",
    "            r50 = metric.Recall_at_k_batch(recon_batch, heldout_data, 50)\n",
    "\n",
    "            n100_list.append(n100)\n",
    "            r20_list.append(r20)\n",
    "            r50_list.append(r50)\n",
    " \n",
    "    total_loss /= len(range(0, e_N, BATCH_SIZE))\n",
    "    n100_list = np.concatenate(n100_list)\n",
    "    r20_list = np.concatenate(r20_list)\n",
    "    r50_list = np.concatenate(r50_list)\n",
    "\n",
    "    return total_loss, np.mean(n100_list), np.mean(r20_list), np.mean(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "331a9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  100/ 233 batches | ms/batch 303.88 | loss 500.64\n",
      "| epoch   1 |  200/ 233 batches | ms/batch 310.54 | loss 489.75\n",
      "[[ 2.5297163  3.7215118  3.393741  ... -8.467041  -6.306715  -5.451406 ]\n",
      " [ 9.12305    6.7557364  9.549453  ... -5.997225  -3.2053828 -3.043894 ]\n",
      " [ 1.2308468  3.624673   3.4980795 ... -7.4248533 -5.880217  -6.5763063]\n",
      " ...\n",
      " [ 8.72814    7.5815115       -inf ... -6.526969  -3.9660323 -2.9830413]\n",
      " [ 7.0993967  8.468171   8.501972  ... -7.9216433 -4.5560913 -4.716062 ]\n",
      " [ 5.424831   5.341018   5.2050986 ... -9.023245  -5.535694  -5.905982 ]]\n",
      "9849490\n",
      "[[ 2.0144613  1.7551389  3.0682101 ... -6.842961  -5.2082124 -5.1703897]\n",
      " [ 2.1583645  5.862558   4.262864  ... -7.9869204 -6.508235  -5.5605593]\n",
      " [ 0.9931089       -inf  5.202327  ... -7.002199  -6.327378  -4.776379 ]\n",
      " ...\n",
      " [ 1.7197454  5.0536904  3.7882335 ... -8.038582  -6.2557335 -4.508086 ]\n",
      " [ 3.3442798  3.187984   3.17373   ... -5.679262  -2.9605439 -4.352285 ]\n",
      " [ 3.926261   6.18427         -inf ... -8.404306  -5.9804263 -5.7177715]]\n",
      "9748985\n",
      "[[ 1.4795444  4.3174205  3.4530349 ... -6.2341337 -5.779947  -4.1553683]\n",
      " [ 2.3556483  4.84978    3.9762728 ... -7.3639226 -6.421962  -6.523755 ]\n",
      " [ 2.5144675  5.021621   4.0746007 ... -3.3326743 -1.787265  -2.840941 ]\n",
      " ...\n",
      " [ 6.197519   8.1423025  8.8847685 ... -6.4924793 -4.172084  -3.403064 ]\n",
      " [ 3.854554   5.983629   3.3616452 ... -7.8027678 -5.4656105 -6.9307013]\n",
      " [ 5.4406424  6.55175    6.172869  ... -8.362513  -5.0102253 -6.152789 ]]\n",
      "9708783\n",
      "[[ 4.037121   5.615907   3.7877781 ... -3.6598935 -2.255354  -3.1687357]\n",
      " [ 7.1936746  7.486564   6.5242534 ... -6.0411477 -3.9559867 -4.86196  ]\n",
      " [ 5.845063   5.2903805  6.3803353 ... -7.1821413 -4.575281  -5.044288 ]\n",
      " ...\n",
      " [ 2.2664058  3.6807458  3.984965  ... -6.9435368 -5.4600744 -4.510051 ]\n",
      " [ 1.5709105  5.6015406  2.1121502 ... -5.5187893 -4.831156  -5.3208075]\n",
      " [ 1.3614073  3.3889909  2.3645184 ... -4.5302973 -5.2274175 -5.3580976]]\n",
      "9769086\n",
      "[[ 2.182273   5.9314446  5.120484  ... -7.457098  -5.939695  -4.640895 ]\n",
      " [ 1.4764165  3.70794    4.59564   ... -7.88342   -6.134986  -5.120076 ]\n",
      " [ 2.0869691  4.244531   4.579914  ... -6.4960794 -5.341514  -5.613751 ]\n",
      " ...\n",
      " [      -inf  8.909736   8.772169  ... -5.8859854 -3.664283  -3.9737976]\n",
      " [ 2.086499   5.0011506  4.6697164 ... -7.6825643 -5.804445  -5.7878623]\n",
      " [ 1.9040102  3.1418927  1.4421937 ... -5.2418203 -5.033821  -5.315483 ]]\n",
      "9769086\n",
      "[[ 8.767096    7.360338    8.357602   ... -6.520668   -3.4866028\n",
      "  -3.5498986 ]\n",
      " [ 3.4890332   3.4375494   2.1474586  ... -5.4601088  -4.481105\n",
      "  -5.2497516 ]\n",
      " [ 5.1264024   3.1581473         -inf ... -6.9503536  -5.4875445\n",
      "  -6.236547  ]\n",
      " ...\n",
      " [ 6.484406    7.6938753   8.750415   ... -6.2774596  -4.1625614\n",
      "  -3.3761292 ]\n",
      " [ 0.05866835  3.8911808   4.22351    ... -7.0879593  -6.134347\n",
      "  -4.734537  ]\n",
      " [ 3.466307    3.5008826   2.9734242  ... -8.40848    -5.3722157\n",
      "  -5.7847624 ]]\n",
      "9789187\n",
      "[[ 0.15032345  4.3027143   4.5720696  ... -5.9887447  -5.28635\n",
      "  -2.9130092 ]\n",
      " [ 7.453201    8.540318   10.514269   ... -7.053412   -4.2830772\n",
      "  -3.672796  ]\n",
      " [ 0.34279433  2.656907    3.917912   ... -6.3099194  -5.4900026\n",
      "  -5.757575  ]\n",
      " ...\n",
      " [ 0.31433433  4.0425873   4.2804685  ... -7.1085906  -5.923235\n",
      "  -5.0639706 ]\n",
      " [ 2.6926856   4.740223    5.1894016  ... -8.100609   -5.9984875\n",
      "  -3.9398959 ]\n",
      " [ 4.9286647   3.5922868   3.2620978  ... -7.613219   -5.2910223\n",
      "  -6.073135  ]]\n",
      "9829389\n",
      "[[ 3.6571562       -inf  3.2382998 ... -8.466206  -5.628568  -6.544981 ]\n",
      " [ 4.0215187  3.326585   4.1426516 ... -8.414673  -6.0363135 -6.4493093]\n",
      " [ 1.640175   4.075364   3.0180457 ... -5.3753214 -5.2665377 -4.2081366]\n",
      " ...\n",
      " [ 2.9660666  4.2248163  1.7915075 ... -5.2440286 -4.534891  -4.751279 ]\n",
      " [ 2.8941386  2.2601182  1.9738343 ... -7.2967105 -6.151958  -6.7570753]\n",
      " [ 5.426455   5.9025216  4.2648683 ... -6.8822093 -4.8529725 -5.0705   ]]\n",
      "9769086\n",
      "[[ 2.802914   3.4749398  2.0694964 ... -6.2755833 -5.4046044 -4.7822227]\n",
      " [ 1.7456698  3.6821938  4.1796465 ... -6.1033015 -5.214651  -4.7792387]\n",
      " [ 2.8523724  4.5859065  5.3556557 ... -8.516253  -6.229655  -4.7271886]\n",
      " ...\n",
      " [ 1.823722   3.5546496  4.0083647 ... -7.51453   -5.35191   -3.7325006]\n",
      " [ 3.1799567  5.4565897  5.45142   ... -7.685364  -5.6586337 -6.5213084]\n",
      " [ 6.832337        -inf  8.597785  ... -7.26166   -4.234184  -4.94778  ]]\n",
      "9688682\n",
      "[[ 0.55625904  1.3712934   1.9813967  ... -5.950416   -5.5886016\n",
      "  -5.9685383 ]\n",
      " [ 7.8353953   6.957765    7.7591143  ... -6.9894514  -3.695912\n",
      "  -5.220833  ]\n",
      " [       -inf  3.4945023   3.9735353  ... -6.3279333  -6.333599\n",
      "  -4.0586753 ]\n",
      " ...\n",
      " [ 0.6722282   2.1990423   3.8284788  ... -5.5193334  -4.7677298\n",
      "  -4.367452  ]\n",
      " [ 3.058577    4.079134    4.1965876  ... -5.1274586  -2.6237822\n",
      "  -3.3101075 ]\n",
      " [ 8.686042    7.9319944  10.21262    ... -7.8808904  -4.45942\n",
      "  -4.9788976 ]]\n",
      "9769086\n",
      "[[ 3.808678   4.6499095  4.5347695 ... -9.136672  -5.948848  -6.1632514]\n",
      " [ 8.650658   7.9124584 10.918068  ... -6.6085167 -3.6501677 -3.0887573]\n",
      " [ 0.602578   4.3384075  2.7990324 ... -6.422407  -6.0237403 -4.8431253]\n",
      " ...\n",
      " [ 2.3872318  3.446939   3.009964  ... -4.647155  -4.46103   -4.798384 ]\n",
      " [ 3.5097806  4.7368364  5.1278005 ... -8.512209  -6.037683  -4.1739774]\n",
      " [ 3.2117915       -inf  4.418528  ... -9.498348  -6.4123106 -6.9651136]]\n",
      "9829389\n",
      "[[ 1.8251714  4.7197356  3.6231272 ... -6.511867  -5.8333144 -4.9245315]\n",
      " [ 0.9117562       -inf  4.8744526 ... -6.6678696 -6.405288  -5.6773915]\n",
      " [ 5.165206   4.5327983  3.9555535 ... -7.553382  -5.4731817 -6.622206 ]\n",
      " ...\n",
      " [ 5.543716   4.3947783  5.280211  ... -8.005668  -5.4185295 -5.003951 ]\n",
      " [ 4.4315476  3.7691126  4.1945906 ... -8.266836  -5.1605096 -5.718225 ]\n",
      " [      -inf  4.177323   4.64739   ... -7.866137  -5.9597282 -5.016878 ]]\n",
      "9869591\n",
      "[[ 8.868292   7.4815645 10.247354  ... -7.1072855 -4.2087708 -3.6826267]\n",
      " [ 1.1564012  4.7594523  4.3797255 ... -6.085137  -6.265768  -3.7766488]\n",
      " [ 5.0810227  5.2265034  4.1979356 ... -7.68169   -5.552277  -6.122411 ]\n",
      " ...\n",
      " [ 7.065197   8.612588  11.042157  ... -7.313576  -4.7078185 -3.8220384]\n",
      " [ 1.6713421  5.7497945  4.4134674 ... -6.403846  -5.3136    -3.7406676]\n",
      " [ 6.4685044  6.435523   5.8244386 ... -6.9031053 -5.004461  -5.3242655]]\n",
      "9789187\n",
      "[[ 3.846235    2.570328    4.3394327  ... -8.432514   -5.6037874\n",
      "  -6.2629848 ]\n",
      " [-0.12227846  4.643112    3.1776161  ... -4.7299213  -5.9555964\n",
      "  -3.7217312 ]\n",
      " [ 0.85115397        -inf  4.861712   ... -7.877904   -6.323605\n",
      "  -5.172371  ]\n",
      " ...\n",
      " [ 7.6622887   8.365609    9.091417   ... -5.852419   -3.8618996\n",
      "  -3.4118865 ]\n",
      " [ 2.5478349         -inf  4.520693   ... -7.650554   -6.070709\n",
      "  -5.723371  ]\n",
      " [ 0.5500347   4.9806595   4.2733583  ... -5.735101   -5.594879\n",
      "  -2.6773288 ]]\n",
      "9829389\n",
      "[[ 3.9993474       -inf  3.6262667 ... -6.983526  -5.596832  -6.743159 ]\n",
      " [ 2.5973854  4.211172   4.1764855 ... -6.5391674 -5.7711596 -5.0749784]\n",
      " [ 3.1031482       -inf  4.680659  ... -7.9736624 -5.5677953 -5.960006 ]\n",
      " ...\n",
      " [ 2.8923957  3.3153255  3.9813097 ... -8.33863   -5.319046  -6.4002075]\n",
      " [ 2.7519386       -inf  4.9281487 ... -7.9979725 -6.008652  -4.869355 ]\n",
      " [      -inf  8.599536   8.885115  ... -6.2403173 -4.278777  -4.241869 ]]\n",
      "9849490\n",
      "[[ 4.378903    5.009458    4.62199    ... -9.139027   -5.77628\n",
      "  -5.936736  ]\n",
      " [ 1.8723555   5.4737425   4.5294013  ... -8.609892   -6.2355833\n",
      "  -5.974061  ]\n",
      " [ 2.833023    3.8629265   3.779785   ... -7.3433676  -6.3113256\n",
      "  -6.75814   ]\n",
      " ...\n",
      " [ 1.5992825   2.629411    1.9927956  ... -4.9329367  -5.602649\n",
      "  -5.0358267 ]\n",
      " [ 1.8210732   3.8397942   3.8322606  ... -8.052907   -6.2378335\n",
      "  -4.887263  ]\n",
      " [ 0.36777428  0.61375177  0.63337046 ... -2.6844952  -5.007083\n",
      "  -4.5167437 ]]\n",
      "9869591\n",
      "[[ 2.5200186  5.165479   5.5730085 ... -8.211252  -5.978367  -4.9889307]\n",
      " [-0.7857077  5.403572   4.1203666 ... -5.3059225 -6.13544   -3.7853117]\n",
      " [ 3.6369593  5.8726077  4.6289787 ... -8.528036  -5.7064004 -4.9807196]\n",
      " ...\n",
      " [ 5.0900974       -inf       -inf ... -6.1023593 -4.7803054 -5.5280037]\n",
      " [ 1.7921834       -inf       -inf ... -6.2889132 -6.066779  -5.8648167]\n",
      " [ 4.68252    6.115651   4.981158  ... -5.4152427 -2.394329  -3.2675893]]\n",
      "9869591\n",
      "[[ 1.7231845   4.680247          -inf ... -7.509506   -5.963297\n",
      "  -6.119708  ]\n",
      " [ 0.56711316  3.8306592   3.3524652  ... -5.5366397  -6.3425684\n",
      "  -3.317307  ]\n",
      " [ 3.6335263   5.5997496   5.087443   ... -8.603945   -5.40889\n",
      "  -6.31301   ]\n",
      " ...\n",
      " [ 8.890256    9.707061          -inf ... -6.5254517  -4.431688\n",
      "  -3.5523632 ]\n",
      " [ 8.200968    9.261611    9.59939    ... -5.5816526  -4.125407\n",
      "  -3.7358575 ]\n",
      " [ 7.5177846   6.534379    8.425077   ... -7.1132717  -4.551021\n",
      "  -4.5720387 ]]\n",
      "9829389\n",
      "[[ 3.892222   6.0217896  4.240969  ... -6.1457453 -4.912298  -5.5226107]\n",
      " [-1.2133098  4.061611   3.429526  ... -4.751518  -5.594703  -3.722966 ]\n",
      " [ 3.356129   4.6285996  3.8586564 ... -5.343524  -2.5433524 -3.4196205]\n",
      " ...\n",
      " [ 2.3365984  4.071146   3.626359  ... -7.679052  -5.625647  -6.4851155]\n",
      " [      -inf  6.813045   9.590578  ... -6.323236  -3.7716303 -4.2864738]\n",
      " [ 4.3248663  3.3974519  4.4862337 ... -7.650674  -5.4291244 -6.251643 ]]\n",
      "9849490\n",
      "[[ 2.3538563  2.72235    3.6492012 ... -6.877235  -5.626207  -5.0606003]\n",
      " [ 8.005878   7.599871        -inf ... -5.167061  -3.9777236 -3.2626135]\n",
      " [ 2.0639393  4.403735   3.1030457 ... -6.2195354 -6.1203923 -4.9945154]\n",
      " ...\n",
      " [ 1.714908   5.6601906  5.6713285 ... -8.373213  -6.2345653 -4.706528 ]\n",
      " [ 2.5363863  3.0789814  1.7629509 ... -6.00714   -5.342666  -6.4921904]\n",
      " [-0.6255932  1.7283049  1.7290941 ... -3.189133  -4.989058  -3.742338 ]]\n",
      "9909793\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 77.03s | valid loss 398.72 | n100 0.360 | r20 0.331 | r50 0.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |  100/ 233 batches | ms/batch 309.39 | loss 487.38\n",
      "| epoch   2 |  200/ 233 batches | ms/batch 299.44 | loss 483.75\n",
      "[[ 2.3573852  3.9840977  3.0259397 ... -8.759146  -6.5207467 -2.9295   ]\n",
      " [ 9.328116   6.735156  10.037076  ... -5.468861  -3.1351607 -1.5714266]\n",
      " [ 0.7464822  3.6029837  3.2585025 ... -7.814021  -5.735282  -4.925503 ]\n",
      " ...\n",
      " [ 9.582179   7.4292645       -inf ... -6.2738676 -3.6981575 -1.6772995]\n",
      " [ 8.109779   9.2650175  9.319821  ... -7.8827605 -3.92268   -4.012914 ]\n",
      " [ 5.756401   5.5305266  5.0233526 ... -9.119161  -5.3155346 -4.66027  ]]\n",
      "9849490\n",
      "[[ 2.3880656  1.3096067  3.5179799 ... -7.1463556 -5.869867  -4.5959783]\n",
      " [ 2.6543422  5.8084702  4.5962195 ... -8.283612  -6.6412764 -3.3218799]\n",
      " [ 1.025841        -inf  5.288585  ... -7.7817807 -7.008975  -3.5331435]\n",
      " ...\n",
      " [ 1.0254346  5.303666   2.6075084 ... -7.8649707 -6.440837  -1.9051402]\n",
      " [ 3.4152987  2.1708546  2.5024831 ... -4.8150268 -2.0880196 -3.7729075]\n",
      " [ 3.9634519  6.4626374       -inf ... -9.103193  -6.3923635 -4.6654844]]\n",
      "9748985\n",
      "[[ 1.878469   4.0685816  3.1518197 ... -6.3879976 -6.2286797 -1.6843964]\n",
      " [ 3.3391697  5.024695   4.350362  ... -8.25197   -6.191516  -5.2654095]\n",
      " [ 2.6976342  4.5113487  4.0091596 ... -3.4750824 -1.5196822 -3.170771 ]\n",
      " ...\n",
      " [ 6.7152143  8.595988   9.080813  ... -6.5718775 -4.2561283 -1.6037328]\n",
      " [ 3.2669928  5.792983   3.0282333 ... -7.3919425 -4.6343665 -4.819858 ]\n",
      " [ 4.906978   6.804116   5.1332498 ... -8.636298  -4.233847  -5.080321 ]]\n",
      "9708783\n",
      "[[ 4.0874114  4.957998   3.607481  ... -3.3725238 -2.5138419 -2.0154345]\n",
      " [ 7.866896   7.948548   6.828572  ... -5.969236  -3.6458037 -3.7345924]\n",
      " [ 6.115114   5.6583576  6.6314917 ... -7.1127434 -4.557073  -4.1250005]\n",
      " ...\n",
      " [ 2.517787   3.381267   3.5855384 ... -7.143812  -5.644977  -1.8124944]\n",
      " [ 0.8355381  6.324732   1.8590403 ... -5.410137  -5.3389254 -3.3725762]\n",
      " [ 2.6799126  3.3154173  3.0514147 ... -5.343923  -5.3526998 -4.190018 ]]\n",
      "9769086\n",
      "[[ 2.6547315  5.5191436  5.5316877 ... -7.89839   -6.4851713 -2.9044771]\n",
      " [ 1.7392776  3.0621865  5.0608745 ... -8.014709  -6.4725275 -3.023262 ]\n",
      " [ 2.305      4.2903624  4.9146357 ... -6.716869  -5.764764  -4.694823 ]\n",
      " ...\n",
      " [      -inf  8.909267   9.204631  ... -6.053903  -3.3332918 -2.7875216]\n",
      " [ 2.0544672  5.803096   4.1373205 ... -8.310096  -6.2648315 -4.168741 ]\n",
      " [ 3.2954223  3.3257139  1.9486322 ... -5.6024895 -4.9945464 -3.9137163]]\n",
      "9769086\n",
      "[[ 8.570005    6.5411296   8.097912   ... -6.106827   -3.4591253\n",
      "  -1.8997674 ]\n",
      " [ 3.5844915   3.1402175   2.0156667  ... -5.7917514  -4.5357413\n",
      "  -3.7825937 ]\n",
      " [ 5.4639683   2.7324939         -inf ... -7.0982647  -5.418701\n",
      "  -5.2744236 ]\n",
      " ...\n",
      " [ 6.9448543   7.8888125   9.6441555  ... -6.4325027  -4.5208683\n",
      "  -1.4773047 ]\n",
      " [-0.70575964  3.959618    3.1106193  ... -7.054843   -6.1163116\n",
      "  -2.9614654 ]\n",
      " [ 3.1869836   2.9711804   2.9429889  ... -8.219372   -4.983231\n",
      "  -3.4758534 ]]\n",
      "9789187\n",
      "[[ 0.2054638   5.0027113   4.7254586  ... -6.8498254  -5.9948034\n",
      "  -0.8487579 ]\n",
      " [ 7.918983    9.239031   10.716913   ... -7.2075734  -4.385821\n",
      "  -2.4049318 ]\n",
      " [ 1.032911    2.245951    4.472007   ... -6.8294315  -5.7150226\n",
      "  -4.5342474 ]\n",
      " ...\n",
      " [ 0.60146743  2.9536824   4.323737   ... -7.1297493  -6.4269238\n",
      "  -3.7111697 ]\n",
      " [ 2.6950493   4.310423    4.700251   ... -8.331905   -6.692675\n",
      "  -1.8983992 ]\n",
      " [ 5.481026    3.8802598   3.6862447  ... -7.943769   -5.1437435\n",
      "  -4.6283665 ]]\n",
      "9829389\n",
      "[[ 3.9758952       -inf  3.4297228 ... -8.999168  -5.4275355 -4.674879 ]\n",
      " [ 4.363874   2.8765996  4.1596293 ... -8.662573  -6.116938  -5.1301813]\n",
      " [ 2.531676   3.7565217  3.4660194 ... -5.969744  -5.435785  -2.6150692]\n",
      " ...\n",
      " [ 2.9494789  4.597151   2.0067346 ... -5.3600874 -5.0963435 -3.0877001]\n",
      " [ 3.005745   2.185195   1.9211112 ... -7.4551535 -5.5017333 -4.675313 ]\n",
      " [ 5.7008944  6.4518967  4.4046063 ... -7.1503673 -4.749575  -3.3909945]]\n",
      "9769086\n",
      "[[ 3.3810437  3.2652714  2.0651922 ... -6.4115148 -5.6523876 -2.5618439]\n",
      " [ 2.7688956  2.568036   4.0930777 ... -6.6033497 -5.6314917 -3.9531183]\n",
      " [ 3.344473   3.565685   5.951083  ... -8.4903345 -6.856709  -3.0890927]\n",
      " ...\n",
      " [ 1.8645525  3.1952114  3.6010566 ... -7.7415314 -5.3996425 -2.0566719]\n",
      " [ 3.286121   5.696588   5.81164   ... -7.935694  -5.6609163 -5.758178 ]\n",
      " [ 7.289607        -inf  9.021872  ... -7.295193  -3.3138409 -4.578699 ]]\n",
      "9688682\n",
      "[[-0.10887045  1.3424411   1.1875653  ... -6.2580223  -5.23035\n",
      "  -4.261595  ]\n",
      " [ 8.375521    7.33045     8.012849   ... -7.019253   -2.945178\n",
      "  -4.817681  ]\n",
      " [       -inf  2.6949332   4.843334   ... -6.3246465  -7.1896048\n",
      "  -2.005003  ]\n",
      " ...\n",
      " [ 0.97293705  1.6045556   4.0314054  ... -5.829063   -5.117005\n",
      "  -2.9476879 ]\n",
      " [ 2.9241784   3.3610728   3.8217993  ... -4.712066   -2.7715201\n",
      "  -2.4763956 ]\n",
      " [ 9.453293    8.75522    10.373948   ... -7.787773   -3.4947371\n",
      "  -4.5125732 ]]\n",
      "9769086\n",
      "[[  4.513512     4.918002     5.357414   ...  -9.407644    -5.706348\n",
      "   -4.5419583 ]\n",
      " [  9.009784     7.8258123   11.189881   ...  -6.4374146   -3.6568413\n",
      "   -1.9327922 ]\n",
      " [  0.83344704   3.6371195    2.8677003  ...  -6.9794707   -6.312717\n",
      "   -2.7099993 ]\n",
      " ...\n",
      " [  3.046117     3.067926     3.454167   ...  -4.552677    -4.372909\n",
      "   -3.5287955 ]\n",
      " [  3.8978484    4.6735606    5.1857677  ...  -8.975153    -6.3008933\n",
      "   -1.8304033 ]\n",
      " [  3.0946035          -inf   4.1595006  ... -10.120472    -5.8257523\n",
      "   -5.138919  ]]\n",
      "9829389\n",
      "[[ 3.0892096  4.525123   3.790993  ... -7.1059275 -5.854551  -2.8000133]\n",
      " [ 2.141203        -inf  5.731331  ... -7.367324  -6.6771903 -4.545775 ]\n",
      " [ 4.8433414  4.7650595  3.9480586 ... -7.533915  -4.595708  -5.1219797]\n",
      " ...\n",
      " [ 5.7745895  4.168314   5.229786  ... -8.013354  -5.229985  -3.4699702]\n",
      " [ 5.1655655  3.57835    4.581253  ... -8.402575  -4.7778435 -4.4417086]\n",
      " [      -inf  3.9186862  5.3889966 ... -7.975009  -6.9079485 -2.7243466]]\n",
      "9869591\n",
      "[[ 9.29412    8.094669  10.559914  ... -6.964221  -4.0760055 -2.1836972]\n",
      " [ 2.018694   4.551803   3.9320905 ... -6.615922  -6.724143  -1.4581956]\n",
      " [ 4.826422   5.902685   4.4869905 ... -7.6089764 -5.241641  -3.5744472]\n",
      " ...\n",
      " [ 8.4366255  9.490931  11.441791  ... -7.349955  -4.1735234 -3.0875146]\n",
      " [ 1.862394   5.269609   3.9606364 ... -6.577297  -5.6481757 -1.3096457]\n",
      " [ 6.4147778  7.1752996  5.9703894 ... -7.291904  -5.016946  -3.9197686]]\n",
      "9789187\n",
      "[[ 3.7815266   2.2221842   4.0092053  ... -8.54574    -5.460411\n",
      "  -4.9600554 ]\n",
      " [-0.59579605  4.9321933   2.0952015  ... -5.4351196  -6.8556547\n",
      "  -1.0069953 ]\n",
      " [ 0.29616374        -inf  3.9143941  ... -8.117048   -6.479711\n",
      "  -3.0472324 ]\n",
      " ...\n",
      " [ 7.977217    9.328278    9.488083   ... -6.0881176  -3.976449\n",
      "  -2.0821738 ]\n",
      " [ 2.442951          -inf  4.397418   ... -7.727099   -6.397583\n",
      "  -3.633965  ]\n",
      " [ 0.7971382   3.9497805   4.38135    ... -5.9331746  -6.4855657\n",
      "  -0.18008518]]\n",
      "9829389\n",
      "[[ 3.4440932       -inf  3.071109  ... -7.112049  -5.247533  -5.018483 ]\n",
      " [ 3.2270463  4.360093   4.232237  ... -7.083164  -6.2480326 -3.7003577]\n",
      " [ 3.29581         -inf  4.630257  ... -8.684062  -5.648337  -4.241394 ]\n",
      " ...\n",
      " [ 3.104973   3.0565512  4.4242473 ... -8.74471   -5.0282164 -5.1271534]\n",
      " [ 3.0128577       -inf  4.8074408 ... -8.457474  -6.1205    -2.4365363]\n",
      " [      -inf  9.799835   9.434614  ... -6.5733385 -3.788284  -3.1888494]]\n",
      "9849490\n",
      "[[ 5.3009925   5.0027056   4.8398747  ... -9.388945   -5.216581\n",
      "  -4.2418723 ]\n",
      " [ 1.758384    5.2381854   4.2562947  ... -8.8165     -5.6828814\n",
      "  -4.2455015 ]\n",
      " [ 3.5824637   4.0268364   4.327359   ... -7.9437995  -6.0382657\n",
      "  -5.0935974 ]\n",
      " ...\n",
      " [ 1.0963334   3.0293872   1.0761077  ... -5.246449   -6.1295233\n",
      "  -2.659176  ]\n",
      " [ 2.3104706   3.0750942   4.213001   ... -7.932112   -6.7025366\n",
      "  -3.698257  ]\n",
      " [ 0.6312576   0.92557275  0.07140332 ... -3.094008   -5.4970627\n",
      "  -2.8748074 ]]\n",
      "9869591\n",
      "[[ 2.6203198  4.872929   5.655296  ... -8.729688  -6.563214  -3.2586274]\n",
      " [-1.7520978  6.054688   3.003668  ... -6.0638456 -6.834757  -1.6375686]\n",
      " [ 3.5356035  6.2163887  4.7437353 ... -8.467291  -6.3498497 -2.863205 ]\n",
      " ...\n",
      " [ 5.5891128       -inf       -inf ... -6.3156166 -3.9207594 -5.170219 ]\n",
      " [ 1.9203128       -inf       -inf ... -6.851187  -5.974638  -4.26311  ]\n",
      " [ 4.6108284  5.3455753  4.2424836 ... -5.119787  -2.0095623 -2.4839988]]\n",
      "9869591\n",
      "[[ 1.56878    5.036815        -inf ... -7.8521247 -5.6202044 -4.6298265]\n",
      " [ 0.7448103  4.1056614  2.7662973 ... -6.0239587 -7.007365  -0.8514265]\n",
      " [ 3.5791402  6.003604   5.067974  ... -9.562948  -5.603389  -4.6985736]\n",
      " ...\n",
      " [ 9.852172  10.220291        -inf ... -6.7965784 -4.232595  -2.2687385]\n",
      " [ 9.552565   9.680562  10.62122   ... -5.7077327 -3.8868196 -2.7698154]\n",
      " [ 8.935782   7.5229177  9.527539  ... -6.679191  -4.073769  -2.8761775]]\n",
      "9829389\n",
      "[[ 5.0752335  6.213335   5.32019   ... -6.526365  -4.913562  -4.0243564]\n",
      " [-1.6789657  4.2129564  2.860062  ... -5.175078  -6.2558722 -1.9137145]\n",
      " [ 3.366268   3.89254    3.1849074 ... -5.120523  -2.5692537 -3.0020773]\n",
      " ...\n",
      " [ 3.3818505  4.5566     3.838575  ... -8.0960655 -4.928786  -5.212093 ]\n",
      " [      -inf  6.895746  10.087876  ... -6.4143796 -3.4350011 -3.8359065]\n",
      " [ 5.68333    2.6054745  4.920595  ... -7.9756484 -4.6818233 -5.1872234]]\n",
      "9849490\n",
      "[[ 2.2415717   1.9725392   3.0845804  ... -6.8955007  -6.403472\n",
      "  -3.5388474 ]\n",
      " [ 9.149091    7.3378005         -inf ... -4.922962   -3.4643805\n",
      "  -2.4119062 ]\n",
      " [ 3.013489    4.493923    3.2250316  ... -6.6525145  -6.320798\n",
      "  -3.4170735 ]\n",
      " ...\n",
      " [ 1.3022933   5.3735495   5.0014043  ... -8.837693   -6.535021\n",
      "  -2.9063888 ]\n",
      " [ 3.6656964   2.546076    1.8447322  ... -6.3565636  -4.843901\n",
      "  -4.725631  ]\n",
      " [ 0.22127688  0.81605256  1.7670681  ... -3.2614038  -5.534742\n",
      "  -1.9862547 ]]\n",
      "9909793\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 75.98s | valid loss 393.81 | n100 0.374 | r20 0.346 | r50 0.478\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_n100 = -np.inf\n",
    "update_count = 0\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss, n100, r20, r50 = evaluate(vad_data_tr, vad_data_te)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
    "                'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
    "                    epoch, time.time() - epoch_start_time, val_loss,\n",
    "                    n100, r20, r50))\n",
    "        print('-' * 89)\n",
    "\n",
    "        n_iter = epoch * len(range(0, N, BATCH_SIZE))\n",
    "        writer.add_scalars('data/loss', {'valid': val_loss}, n_iter)\n",
    "        writer.add_scalar('data/n100', n100, n_iter)\n",
    "        writer.add_scalar('data/r20', r20, n_iter)\n",
    "        writer.add_scalar('data/r50', r50, n_iter)\n",
    "\n",
    "        # Save the model if the n100 is the best we've seen so far.\n",
    "        if n100 > best_n100:\n",
    "            with open(SAVE_PATH, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_n100 = n100\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3f3a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "MODEL_PATH = SAVE_PATH\n",
    "with open(SAVE_PATH, 'rb') as f:\n",
    "    model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19c6cc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 392.09 | n100 0.38 | r20 0.35 | r50 0.48\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss, n100, r20, r50 = evaluate(test_data_tr, test_data_te)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
    "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4820f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "126ad097-15ac-47df-a45e-4557e76d71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_inverse(x):\n",
    "    return -np.log(-np.log(x))\n",
    "\n",
    "def evaluate_expectation(data_tr, data_te, n_sampling=1):\n",
    "    # Turn on evaluation mode\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    global update_count\n",
    "    e_idxlist = list(range(data_tr.shape[0]))\n",
    "    e_N = data_tr.shape[0]\n",
    "    n100_list = []\n",
    "    r20_list = []\n",
    "    r50_list = []\n",
    "    n100_list_per_sampling = []\n",
    "    r20_list_per_sampling = []\n",
    "    r50_list_per_sampling = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, e_N, BATCH_SIZE):\n",
    "            end_idx = min(start_idx + BATCH_SIZE, N)\n",
    "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
    "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
    "    \n",
    "            u_idxlist_wo_any_iteracts = [i for i, x in enumerate(heldout_data.toarray().sum(axis=1)) if x >0]\n",
    "            data = data[u_idxlist_wo_any_iteracts]\n",
    "            heldout_data = heldout_data[u_idxlist_wo_any_iteracts]\n",
    "            \n",
    "            data_tensor = naive_sparse2tensor(data).to(device)\n",
    "\n",
    "            if TOTAL_ANNEAL_STEPS > 0:\n",
    "                anneal = min(ANNEAL_CAP, \n",
    "                               1. * update_count / TOTAL_ANNEAL_STEPS)\n",
    "            else:\n",
    "                anneal = ANNEAL_CAP\n",
    "\n",
    "            recon_batch, mu, logvar = model(data_tensor)\n",
    "\n",
    "            loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Exclude examples from training set\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            # recon_batch[data.nonzero()] = -np.inf\n",
    "\n",
    "            for l in range(n_sampling):\n",
    "                # Add Gumbel samples\n",
    "                np.random.seed(seed=l)\n",
    "                recon_batch_gumbel_sampled = np.vectorize(np.log)(recon_batch) + np.vectorize(gumbel_inverse)(np.random.uniform(size=recon_batch.shape))\n",
    "                # recon_batch_gumbel_sampled = recon_batch + np.vectorize(gumbel_inverse)(np.random.uniform(size=recon_batch.shape))\n",
    "                recon_batch_gumbel_sampled[data.nonzero()] = -np.inf\n",
    "\n",
    "                n100_list_per_sampling.append(metric.NDCG_binary_at_k_batch(recon_batch_gumbel_sampled, heldout_data, 100))\n",
    "                r20_list_per_sampling.append(metric.Recall_at_k_batch(recon_batch_gumbel_sampled, heldout_data, 20))\n",
    "                r50_list_per_sampling.append(metric.Recall_at_k_batch(recon_batch_gumbel_sampled, heldout_data, 50))\n",
    "\n",
    "            n100_list.append(np.concatenate(n100_list_per_sampling))\n",
    "            r20_list.append(np.concatenate(r20_list_per_sampling))\n",
    "            r50_list.append(np.concatenate(r50_list_per_sampling))\n",
    "    \n",
    "    total_loss /= len(range(0, e_N, BATCH_SIZE))\n",
    "    n100_list = np.concatenate(n100_list)\n",
    "    r20_list = np.concatenate(r20_list)\n",
    "    r50_list = np.concatenate(r50_list)\n",
    "\n",
    "    return total_loss, n100_list, r20_list, r50_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee9a7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "MODEL_PATH = SAVE_PATH\n",
    "with open(SAVE_PATH, 'rb') as f:\n",
    "    model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00d678fd-d2e7-47c2-ab85-ee0bd8030da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575323"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_tr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66516dd0-1d22-4224-973c-4199c686bb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138922"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_te.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5b73ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 392.09 | n100 0.19(0.00) | r20 0.15(0.00) | r50 0.29(0.00)\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss, n100_list, r20_list, r50_list = evaluate_expectation(test_data_tr, test_data_te, n_sampling=10)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:4.2f} | n100 {:4.2f}({:4.2f}) | r20 {:4.2f}({:4.2f}) | '\n",
    "        'r50 {:4.2f}({:4.2f})'.format(test_loss, np.mean(n100_list), np.std(n100_list)/np.sqrt(len(n100_list)), np.mean(r20_list), np.std(r20_list)/np.sqrt(len(r20_list)), np.mean(r50_list), np.std(r50_list)/np.sqrt(len(r50_list))))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f07230-1d9e-4b67-8f66-86a4cdaf91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on test data.\n",
    "test_loss, n100_list, r20_list, r50_list = evaluate_expectation(test_data_tr, test_data_te, n_sampling=2)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:4.2f} | n100 {:4.2f}({:4.2f}) | r20 {:4.2f}({:4.2f}) | '\n",
    "        'r50 {:4.2f}({:4.2f})'.format(test_loss, np.mean(n100_list), np.std(n100_list)/np.sqrt(len(n100_list)), np.mean(r20_list), np.std(r20_list)/np.sqrt(len(r20_list)), np.mean(r50_list), np.std(r50_list)/np.sqrt(len(r50_list))))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a317285-b4cb-4eff-8868-d5ef8560f5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028954382097746783"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(n100_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb29f47-47af-4cda-9f29-987588df02cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea5c41-bef5-4c11-920b-d56a04293aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc803cf5-1add-4814-ab04-415eed2c2f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ea380a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014261365424167457"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(n100_list)/np.sqrt(len(n100_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c971c6b-d11c-485a-8602-c697f01b74a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1937028339562343"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(n100_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34d3a8d3-0412-4c64-954d-bd4fe7695ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16077533, 0.07577172, 0.09345934, 0.87696311, 0.73854203,\n",
       "        0.97151376, 0.23231911, 0.01203572, 0.79877261, 0.65784319,\n",
       "        0.54884241, 0.99816819, 0.89532786, 0.03135016, 0.80002473,\n",
       "        0.10875814, 0.90268886, 0.13096327, 0.46018749, 0.25533866],\n",
       "       [0.56584901, 0.06728489, 0.55103154, 0.53706195, 0.84778836,\n",
       "        0.55772548, 0.85846841, 0.11341186, 0.76989669, 0.39311703,\n",
       "        0.83199332, 0.08058243, 0.38528321, 0.29842911, 0.75579901,\n",
       "        0.5148304 , 0.1684486 , 0.61322506, 0.30408593, 0.63281014],\n",
       "       [0.48189487, 0.91280326, 0.05150981, 0.11489613, 0.02540707,\n",
       "        0.32868316, 0.53711695, 0.70723588, 0.24563607, 0.40671792,\n",
       "        0.96080528, 0.97333487, 0.30816792, 0.30772908, 0.94006582,\n",
       "        0.69751954, 0.55233989, 0.92514497, 0.45471685, 0.33267487],\n",
       "       [0.91547462, 0.79492209, 0.21760611, 0.96670685, 0.83208177,\n",
       "        0.53495635, 0.66099052, 0.5519144 , 0.11217892, 0.20314909,\n",
       "        0.85909234, 0.18021768, 0.948474  , 0.83220091, 0.99905396,\n",
       "        0.15688832, 0.28602236, 0.56722629, 0.43756427, 0.95224451],\n",
       "       [0.79416992, 0.78750294, 0.06002281, 0.43792986, 0.80574274,\n",
       "        0.58004337, 0.26747532, 0.35629732, 0.64334356, 0.436437  ,\n",
       "        0.73217242, 0.7692485 , 0.42763419, 0.69683035, 0.313147  ,\n",
       "        0.80748042, 0.31258607, 0.14913949, 0.79144317, 0.03355824],\n",
       "       [0.63130446, 0.12548547, 0.29019438, 0.34963258, 0.68545087,\n",
       "        0.19123605, 0.09915244, 0.70882277, 0.24766766, 0.22434615,\n",
       "        0.50688097, 0.58600968, 0.96364504, 0.06752905, 0.2636648 ,\n",
       "        0.50473006, 0.23333477, 0.17977741, 0.79594594, 0.5210128 ],\n",
       "       [0.98559897, 0.75446133, 0.10290177, 0.47245374, 0.89038684,\n",
       "        0.87869513, 0.05045335, 0.36336797, 0.20306971, 0.71380313,\n",
       "        0.01832118, 0.9490229 , 0.58779714, 0.01823153, 0.30043505,\n",
       "        0.15013677, 0.89108593, 0.58564666, 0.91955333, 0.29973997],\n",
       "       [0.85583962, 0.31232881, 0.59637844, 0.99412281, 0.12882444,\n",
       "        0.68922353, 0.9813803 , 0.08847731, 0.74397942, 0.67155234,\n",
       "        0.53280339, 0.11311946, 0.78051557, 0.22326957, 0.45117335,\n",
       "        0.22457854, 0.68595121, 0.49235988, 0.30061718, 0.36720287],\n",
       "       [0.00721984, 0.34169795, 0.14884892, 0.79074804, 0.09776859,\n",
       "        0.46631452, 0.85923136, 0.82029859, 0.38610804, 0.08091183,\n",
       "        0.41266441, 0.65383319, 0.14081809, 0.63932174, 0.60435494,\n",
       "        0.83358722, 0.63208078, 0.04604067, 0.80257154, 0.88403383],\n",
       "       [0.91211599, 0.74656676, 0.27570963, 0.4492661 , 0.60078187,\n",
       "        0.57749827, 0.4769789 , 0.54344357, 0.88184647, 0.2936838 ,\n",
       "        0.19072993, 0.29575107, 0.61141942, 0.17414958, 0.73805299,\n",
       "        0.00485011, 0.63208702, 0.80495148, 0.82367007, 0.45921981]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.uniform(size=[10,20])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6b94c03-0c5b-4f45-a3db-7b46548ea572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.03084264e-01, -9.47801091e-01, -8.62986511e-01,\n",
       "         2.03034398e+00,  1.19376752e+00,  3.54391892e+00,\n",
       "        -3.78192130e-01, -1.48611174e+00,  1.49308273e+00,\n",
       "         8.70388805e-01,  5.10919089e-01,  6.30153416e+00,\n",
       "         2.20214896e+00, -1.24200121e+00,  1.50007852e+00,\n",
       "        -7.96889345e-01,  2.27908977e+00, -7.09433047e-01,\n",
       "         2.53446483e-01, -3.11274954e-01],\n",
       "       [ 5.63122921e-01, -9.92814511e-01,  5.17576305e-01,\n",
       "         4.75391181e-01,  1.80105704e+00,  5.38045392e-01,\n",
       "         1.87989980e+00, -7.77823433e-01,  1.34132502e+00,\n",
       "         6.86558720e-02,  1.69319534e+00, -9.23653438e-01,\n",
       "         4.73258105e-02, -1.89977898e-01,  1.27303785e+00,\n",
       "         4.09596994e-01, -5.77244964e-01,  7.15345206e-01,\n",
       "        -1.74327150e-01,  7.81792978e-01],\n",
       "       [ 3.14670613e-01,  2.39431763e+00, -1.08720853e+00,\n",
       "        -7.71832094e-01, -1.30093470e+00, -1.06754482e-01,\n",
       "         4.75555936e-01,  1.06018698e+00, -3.39257098e-01,\n",
       "         1.05765706e-01,  3.21928810e+00,  3.61091535e+00,\n",
       "        -1.63062669e-01, -1.64272557e-01,  2.78376480e+00,\n",
       "         1.02102715e+00,  5.21563600e-01,  2.55355182e+00,\n",
       "         2.38155206e-01, -9.58460552e-02],\n",
       "       [ 2.42687210e+00,  1.47180356e+00, -4.22039454e-01,\n",
       "         3.38552151e+00,  1.69377347e+00,  4.69091851e-01,\n",
       "         8.81851204e-01,  5.20266190e-01, -7.82832582e-01,\n",
       "        -4.66130596e-01,  1.88467201e+00, -5.38590478e-01,\n",
       "         2.93933495e+00,  1.69455259e+00,  6.96275727e+00,\n",
       "        -6.16385487e-01, -2.24490881e-01,  5.67401332e-01,\n",
       "         1.90517021e-01,  3.01729436e+00],\n",
       "       [ 1.46768737e+00,  1.43175973e+00, -1.03426244e+00,\n",
       "         1.91527981e-01,  1.53251958e+00,  6.07607496e-01,\n",
       "        -2.76667612e-01, -3.14887249e-02,  8.18537201e-01,\n",
       "         1.87400935e-01,  1.16558820e+00,  1.33810928e+00,\n",
       "         1.63122479e-01,  1.01828665e+00, -1.49352801e-01,\n",
       "         1.54254371e+00, -1.50895757e-01, -6.43364979e-01,\n",
       "         1.45287357e+00, -1.22214847e+00],\n",
       "       [ 7.76600467e-01, -7.30233557e-01, -2.12854249e-01,\n",
       "        -4.96207165e-02,  9.73712088e-01, -5.03345754e-01,\n",
       "        -8.37722226e-01,  1.06667839e+00, -3.33372802e-01,\n",
       "        -4.01835270e-01,  3.86428849e-01,  6.26575149e-01,\n",
       "         3.29596573e+00, -9.91471454e-01, -2.87489555e-01,\n",
       "         3.80189950e-01, -3.75199057e-01, -5.40016871e-01,\n",
       "         1.47742760e+00,  4.27740365e-01],\n",
       "       [ 4.23321144e+00,  1.26673065e+00, -8.21531773e-01,\n",
       "         2.87928167e-01,  2.15330978e+00,  2.04548633e+00,\n",
       "        -1.09417113e+00, -1.22637706e-02, -4.66375786e-01,\n",
       "         1.08723303e+00, -1.38621871e+00,  2.95033172e+00,\n",
       "         6.32290329e-01, -1.38744437e+00, -1.84422418e-01,\n",
       "        -6.39856412e-01,  2.16009285e+00,  6.25416310e-01,\n",
       "         2.47852019e+00, -1.86346747e-01],\n",
       "       [ 1.86000228e+00, -1.51603531e-01,  6.59944835e-01,\n",
       "         5.13373108e+00, -7.17500574e-01,  9.88351768e-01,\n",
       "         3.97415221e+00, -8.85835283e-01,  1.21826817e+00,\n",
       "         9.20892987e-01,  4.62666129e-01, -7.79008693e-01,\n",
       "         1.39513093e+00, -4.05048624e-01,  2.28277159e-01,\n",
       "        -4.01142310e-01,  9.75645963e-01,  3.44541198e-01,\n",
       "        -1.83918323e-01, -1.83911695e-03],\n",
       "       [-1.59552600e+00, -7.12299497e-02, -6.44389328e-01,\n",
       "         1.44912385e+00, -8.43785397e-01,  2.70634955e-01,\n",
       "         1.88573794e+00,  1.61904962e+00,  4.95705137e-02,\n",
       "        -9.22032326e-01,  1.22031402e-01,  8.55894320e-01,\n",
       "        -6.73090556e-01,  8.04419717e-01,  6.85985662e-01,\n",
       "         1.70365551e+00,  7.79275878e-01, -1.12435481e+00,\n",
       "         1.51442652e+00,  2.09345973e+00],\n",
       "       [ 2.38609594e+00,  1.23007643e+00, -2.53406590e-01,\n",
       "         2.22968658e-01,  6.74279575e-01,  5.99566082e-01,\n",
       "         3.00722693e-01,  4.94576024e-01,  2.07356038e+00,\n",
       "        -2.03146199e-01, -5.04946463e-01, -1.97404855e-01,\n",
       "         7.09333271e-01, -5.58381151e-01,  1.19158436e+00,\n",
       "        -1.67311761e+00,  7.79297381e-01,  1.52798109e+00,\n",
       "         1.63997325e+00,  2.50737933e-01]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(gumbel_inverse)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02a8307d-cb38-4919-9409-8afc02b882e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.03084264e-01, -9.47801091e-01, -8.62986511e-01,\n",
       "         2.03034398e+00,  1.19376752e+00,  3.54391892e+00,\n",
       "        -3.78192130e-01, -1.48611174e+00,  1.49308273e+00,\n",
       "         8.70388805e-01,  5.10919089e-01,  6.30153416e+00,\n",
       "         2.20214896e+00, -1.24200121e+00,  1.50007852e+00,\n",
       "        -7.96889345e-01,  2.27908977e+00, -7.09433047e-01,\n",
       "         2.53446483e-01, -3.11274954e-01],\n",
       "       [ 5.63122921e-01, -9.92814511e-01,  5.17576305e-01,\n",
       "         4.75391181e-01,  1.80105704e+00,  5.38045392e-01,\n",
       "         1.87989980e+00, -7.77823433e-01,  1.34132502e+00,\n",
       "         6.86558720e-02,  1.69319534e+00, -9.23653438e-01,\n",
       "         4.73258105e-02, -1.89977898e-01,  1.27303785e+00,\n",
       "         4.09596994e-01, -5.77244964e-01,  7.15345206e-01,\n",
       "        -1.74327150e-01,  7.81792978e-01],\n",
       "       [ 3.14670613e-01,  2.39431763e+00, -1.08720853e+00,\n",
       "        -7.71832094e-01, -1.30093470e+00, -1.06754482e-01,\n",
       "         4.75555936e-01,  1.06018698e+00, -3.39257098e-01,\n",
       "         1.05765706e-01,  3.21928810e+00,  3.61091535e+00,\n",
       "        -1.63062669e-01, -1.64272557e-01,  2.78376480e+00,\n",
       "         1.02102715e+00,  5.21563600e-01,  2.55355182e+00,\n",
       "         2.38155206e-01, -9.58460552e-02],\n",
       "       [ 2.42687210e+00,  1.47180356e+00, -4.22039454e-01,\n",
       "         3.38552151e+00,  1.69377347e+00,  4.69091851e-01,\n",
       "         8.81851204e-01,  5.20266190e-01, -7.82832582e-01,\n",
       "        -4.66130596e-01,  1.88467201e+00, -5.38590478e-01,\n",
       "         2.93933495e+00,  1.69455259e+00,  6.96275727e+00,\n",
       "        -6.16385487e-01, -2.24490881e-01,  5.67401332e-01,\n",
       "         1.90517021e-01,  3.01729436e+00],\n",
       "       [ 1.46768737e+00,  1.43175973e+00, -1.03426244e+00,\n",
       "         1.91527981e-01,  1.53251958e+00,  6.07607496e-01,\n",
       "        -2.76667612e-01, -3.14887249e-02,  8.18537201e-01,\n",
       "         1.87400935e-01,  1.16558820e+00,  1.33810928e+00,\n",
       "         1.63122479e-01,  1.01828665e+00, -1.49352801e-01,\n",
       "         1.54254371e+00, -1.50895757e-01, -6.43364979e-01,\n",
       "         1.45287357e+00, -1.22214847e+00],\n",
       "       [ 7.76600467e-01, -7.30233557e-01, -2.12854249e-01,\n",
       "        -4.96207165e-02,  9.73712088e-01, -5.03345754e-01,\n",
       "        -8.37722226e-01,  1.06667839e+00, -3.33372802e-01,\n",
       "        -4.01835270e-01,  3.86428849e-01,  6.26575149e-01,\n",
       "         3.29596573e+00, -9.91471454e-01, -2.87489555e-01,\n",
       "         3.80189950e-01, -3.75199057e-01, -5.40016871e-01,\n",
       "         1.47742760e+00,  4.27740365e-01],\n",
       "       [ 4.23321144e+00,  1.26673065e+00, -8.21531773e-01,\n",
       "         2.87928167e-01,  2.15330978e+00,  2.04548633e+00,\n",
       "        -1.09417113e+00, -1.22637706e-02, -4.66375786e-01,\n",
       "         1.08723303e+00, -1.38621871e+00,  2.95033172e+00,\n",
       "         6.32290329e-01, -1.38744437e+00, -1.84422418e-01,\n",
       "        -6.39856412e-01,  2.16009285e+00,  6.25416310e-01,\n",
       "         2.47852019e+00, -1.86346747e-01],\n",
       "       [ 1.86000228e+00, -1.51603531e-01,  6.59944835e-01,\n",
       "         5.13373108e+00, -7.17500574e-01,  9.88351768e-01,\n",
       "         3.97415221e+00, -8.85835283e-01,  1.21826817e+00,\n",
       "         9.20892987e-01,  4.62666129e-01, -7.79008693e-01,\n",
       "         1.39513093e+00, -4.05048624e-01,  2.28277159e-01,\n",
       "        -4.01142310e-01,  9.75645963e-01,  3.44541198e-01,\n",
       "        -1.83918323e-01, -1.83911695e-03],\n",
       "       [-1.59552600e+00, -7.12299497e-02, -6.44389328e-01,\n",
       "         1.44912385e+00, -8.43785397e-01,  2.70634955e-01,\n",
       "         1.88573794e+00,  1.61904962e+00,  4.95705137e-02,\n",
       "        -9.22032326e-01,  1.22031402e-01,  8.55894320e-01,\n",
       "        -6.73090556e-01,  8.04419717e-01,  6.85985662e-01,\n",
       "         1.70365551e+00,  7.79275878e-01, -1.12435481e+00,\n",
       "         1.51442652e+00,  2.09345973e+00],\n",
       "       [ 2.38609594e+00,  1.23007643e+00, -2.53406590e-01,\n",
       "         2.22968658e-01,  6.74279575e-01,  5.99566082e-01,\n",
       "         3.00722693e-01,  4.94576024e-01,  2.07356038e+00,\n",
       "        -2.03146199e-01, -5.04946463e-01, -1.97404855e-01,\n",
       "         7.09333271e-01, -5.58381151e-01,  1.19158436e+00,\n",
       "        -1.67311761e+00,  7.79297381e-01,  1.52798109e+00,\n",
       "         1.63997325e+00,  2.50737933e-01]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(-np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f759fb3d-8672-482b-987b-0802d986a41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6030842547304646"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(-np.log(0.16077533))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f00cdd-96c9-4b1f-954c-d11215ea0dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prob-vae-pytorch",
   "language": "python",
   "name": "prob-vae-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
